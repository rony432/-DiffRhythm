
[DEFAULTS]

#name of the run
exp_name = F5

# the batch size
batch_size = 8 

# the chunk size
max_frames = 3000 
min_frames = 10

# number of CPU workers for the DataLoader
num_workers = 4

# the random seed
seed = 42

# Batches for gradient accumulation
accum_batches = 1

# Number of steps between checkpoints
checkpoint_every = 10000                              
                     
# trainer checkpoint file to restart training from
ckpt_path = ''

# model checkpoint file to start a new training run from
pretrained_ckpt_path = ''

# Checkpoint path for the pretransform model if needed
pretransform_ckpt_path = ''

# configuration model specifying model hyperparameters
model_config = ''

# configuration for datasets
dataset_config = ''

# directory to save the checkpoints in
save_dir = ''

# grad norm
max_grad_norm = 1.0

# grad accu
grad_accumulation_steps = 1

# lr
learning_rate = 7.5e-5

# epoch
epochs = 110 

# warmup steps
num_warmup_updates = 2000

# save checkpoint per steps
save_per_updates = 5000

# save last checkpoint per steps
last_per_steps = 5000

prompt_path = "/mnt/sfs/music/lance/style-lance-full|/mnt/sfs/music/lance/style-lance-cnen-music-second"
lrc_path = "/mnt/sfs/music/lance/lrc-lance-emb-full|/mnt/sfs/music/lance/lrc-lance-cnen-second"
latent_path = "/mnt/sfs/music/lance/latent-lance|/mnt/sfs/music/lance/latent-lance-cnen-music-second-1|/mnt/sfs/music/lance/latent-lance-cnen-music-second-2"

audio_drop_prob = 0.3
cond_drop_prob = 0.0
style_drop_prob = 0.1
lrc_drop_prob = 0.1

align_lyrics = 0
lyrics_slice = 0
parse_lyrics = 1
skip_empty_lyrics = 0
lyrics_shift = -1

use_style_prompt = 1

tokenizer_type = gpt2

reset_lr = 0

resumable_with_seed = 666

downsample_rate = 2048

grad_ckpt = 0

dataset_path = "/mnt/sfs/music/hkchen/workspace/F5-TTS-HW/filelists/music123latent_asred_bpmstyle_cnen_pure1"

pure_prob = 0.0